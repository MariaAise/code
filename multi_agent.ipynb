{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbde534",
   "metadata": {},
   "source": [
    "### Multi-agent systems\n",
    "- parallel\n",
    "- sequential\n",
    "- loop \n",
    "\n",
    "\n",
    "Why Multi-Agent Systems?\n",
    "Types and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b27976",
   "metadata": {},
   "source": [
    "1. **Modular Specialization (Role-Playing)** - By narrowing the scope for each agent, you increase the accuracy of that specific sub-task.\n",
    "\n",
    "Even when using the same model (e.g., GPT-4o) for every agent, assigning distinct personas and system prompts reduces \"distraction.\" A single prompt trying to be a coder, a security auditor, and a technical writer often suffers from \"lost in the middle\" context issues.\n",
    "\n",
    "\n",
    "2. **Iterative Refinement (The Critic Loop)** - \"self-correction\" produces significantly higher quality than a single-pass prompt. A single agent is often \"blind\" to its own logical fallacies; a second agent acts as a fresh set of eyes.\n",
    "\n",
    "Multi-agent systems allow for Adversarial or Collaborative loops. One agent generates an output, and another agent is specifically tasked with finding flaws in it.\n",
    "\n",
    "3. **Parallelism and Scalability**\n",
    "In a complex workflow, a multi-agent system can spin up several \"worker\" agents to perform tasks simultaneously.\n",
    "\n",
    "\n",
    "4. **Diverse \"State\" Management** - \"clean\" context window. Instead of one massive prompt containing all tools and all data, each agent only carries the information relevant to its specific job.\n",
    "\n",
    "Different agents can maintain different \"memory\" or \"tools.\"\n",
    "\n",
    "Agent A might have access to a Python interpreter.\n",
    "\n",
    "Agent B might have access to a vector database (RAG).\n",
    "\n",
    "Agent C might have access to a live API.\n",
    "\n",
    "5. Error Isolation\n",
    "If a single-agent prompt fails or hallucinates halfway through a 10-step process, the whole run is usually ruined. In a multi-agent system, you can implement checkpoints.\n",
    "\n",
    "The Benefit: If the \"Researcher Agent\" fails to find data, the system can catch that error and retry that specific step before the \"Writer Agent\" ever starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed7227a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8bafaf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in vs code only \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise RuntimeError(\"missing key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run in VS code\n",
    "# Setup for Colab\n",
    "\n",
    "# set GOOGLE_API_KEY in Colab secrets\n",
    "# the below retrieves the set key from the Colab\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n",
    "    )\n",
    "\n",
    "# helper function to be used \n",
    "\n",
    "# Define helper functions that will be reused throughout the notebook\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from jupyter_server.serverapp import list_running_servers\n",
    "\n",
    "\n",
    "# Gets the proxied URL in the Kaggle Notebooks environment\n",
    "def get_adk_proxy_url():\n",
    "    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n",
    "    ADK_PORT = \"8000\"\n",
    "\n",
    "    servers = list(list_running_servers())\n",
    "    if not servers:\n",
    "        raise Exception(\"No running Jupyter servers found.\")\n",
    "\n",
    "    baseURL = servers[0][\"base_url\"]\n",
    "\n",
    "    try:\n",
    "        path_parts = baseURL.split(\"/\")\n",
    "        kernel = path_parts[2]\n",
    "        token = path_parts[3]\n",
    "    except IndexError:\n",
    "        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n",
    "\n",
    "    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n",
    "    url = f\"{PROXY_HOST}{url_prefix}\"\n",
    "\n",
    "    styled_html = f\"\"\"\n",
    "    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n",
    "            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n",
    "        </div>\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n",
    "            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n",
    "            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n",
    "                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n",
    "                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n",
    "                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n",
    "            </ol>\n",
    "            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n",
    "        </div>\n",
    "        <a href='{url}' target='_blank' style=\"\n",
    "            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n",
    "            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n",
    "            Open ADK Web UI (after running cell below) ‚Üó\n",
    "        </a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    display(HTML(styled_html))\n",
    "\n",
    "    return url_prefix\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d5c60862",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1, # Initial delay before first retry (in seconds)\n",
    "    http_status_codes=[429, 500, 503, 504] # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ research_agent created.\n",
      "‚úÖ summarizer_agent created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Research Agent: Its job is to use the google_search tool and present findings.\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ research_agent created.\")\n",
    "\n",
    "# Summarizer Agent: Its job is to summarize the text it receives.\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ summarizer_agent created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d62351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ research_agent created.\n",
      "‚úÖ summarizer_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Research Agent: Its job is to use the google_search tool and present findings.\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n",
    "    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ research_agent created.\")\n",
    "\n",
    "# Summarizer Agent: Its job is to summarize the text it receives.\n",
    "summarizer_agent = Agent(\n",
    "    name=\"SummarizerAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # The instruction is modified to request a bulleted list for a clear output format.\n",
    "    instruction=\"\"\"Read the provided research findings: {research_findings}\n",
    "Create a concise summary as a bulleted list with 3-5 key points.\"\"\",\n",
    "    output_key=\"final_summary\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ summarizer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ root_agent created.\n"
     ]
    }
   ],
   "source": [
    "# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\n",
    "root_agent = Agent(\n",
    "    name=\"ResearchCoordinator\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n",
    "    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
    "1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n",
    "2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n",
    "3. Finally, present the final summary clearly to the user as your response.\"\"\",\n",
    "    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n",
    "    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ root_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n",
      "1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n",
      "2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n",
      "3. Finally, present the final summary clearly to the user as your response.\n",
      "\n",
      "You are an agent. Your internal name is \"ResearchCoordinator\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}, 'tools': [{}]}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"What are the recent ways to evaluate agentic AI systems in finance? \"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "ResearchAgent: {'request': {'type': <Type.STRING: 'STRING'>}} \n",
      "SummarizerAgent: {'request': {'type': <Type.STRING: 'STRING'>}} \n",
      "-----------------------------------------------------------\n",
      "\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ac1ede0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ab82dd0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30a784560>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > What are the recent ways to evaluate agentic AI systems in finance? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 09:14:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=517'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ...existing code...\u001b[39;00m\n\u001b[32m      2\u001b[39m runner = InMemoryRunner(agent=root_agent)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mWhat are the recent ways to evaluate agentic AI systems in finance? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ...existing code...\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:1168\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1166\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1169\u001b[39m     user_id=user_id,\n\u001b[32m   1170\u001b[39m     session_id=session.id,\n\u001b[32m   1171\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1172\u001b[39m     run_config=run_config,\n\u001b[32m   1173\u001b[39m ):\n\u001b[32m   1174\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1175\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:505\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    500\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    501\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    502\u001b[39m       )\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:493\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    486\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    487\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m     )\n\u001b[32m    492\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    495\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:722\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    719\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    724\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:482\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    481\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1053\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1051\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py:262\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ce.code == \u001b[32m429\u001b[39m:\n\u001b[32m    257\u001b[39m   \u001b[38;5;66;03m# We expect running into a Resource Exhausted error to be a common\u001b[39;00m\n\u001b[32m    258\u001b[39m   \u001b[38;5;66;03m# client error that developers would run into. We enhance the messaging\u001b[39;00m\n\u001b[32m    259\u001b[39m   \u001b[38;5;66;03m# with possible fixes to this issue.\u001b[39;00m\n\u001b[32m    260\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m _ResourceExhaustedError(ce) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mce\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ce\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py:241\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m close_result\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    242\u001b[39m       model=llm_request.model,\n\u001b[32m    243\u001b[39m       contents=llm_request.contents,\n\u001b[32m    244\u001b[39m       config=llm_request.config,\n\u001b[32m    245\u001b[39m   )\n\u001b[32m    246\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    247\u001b[39m   logger.debug(_build_response_log(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:7006\u001b[39m, in \u001b[36mgenerate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6973\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Makes an API request to generate content using a model.\u001b[39;00m\n\u001b[32m   6974\u001b[39m \n\u001b[32m   6975\u001b[39m \u001b[33;03mSome models support multimodal input and output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7002\u001b[39m \u001b[33;03m  # J'aime les bagels.\u001b[39;00m\n\u001b[32m   7003\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   7004\u001b[39m \u001b[38;5;66;03m# Retrieve and cache any MCP sessions if provided.\u001b[39;00m\n\u001b[32m   7005\u001b[39m incompatible_tools_indexes = (\n\u001b[32m-> \u001b[39m\u001b[32m7006\u001b[39m     _extra_utils.find_afc_incompatible_tool_indexes(config)\n\u001b[32m   7007\u001b[39m )\n\u001b[32m   7008\u001b[39m parsed_config, mcp_to_genai_tool_adapters = (\n\u001b[32m   7009\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m _extra_utils.parse_config_for_mcp_sessions(config)\n\u001b[32m   7010\u001b[39m )\n\u001b[32m   7011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _extra_utils.should_disable_afc(parsed_config):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:5824\u001b[39m, in \u001b[36m_generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5822\u001b[39m   if request_url_dict:\n\u001b[32m   5823\u001b[39m     path = '{model}:generateContent'.format_map(request_url_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5824\u001b[39m   else:\n\u001b[32m   5825\u001b[39m     path = '{model}:generateContent'\n\u001b[32m   5826\u001b[39m else:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1434\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1425\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1429\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1430\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1431\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1432\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1435\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1436\u001b[39m   )\n\u001b[32m   1437\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1438\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1367\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1365\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1369\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1347\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1339\u001b[39m   \u001b[38;5;66;03m# aiohttp is not available. Fall back to httpx.\u001b[39;00m\n\u001b[32m   1340\u001b[39m   client_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_httpx_client.request(\n\u001b[32m   1341\u001b[39m       method=http_request.method,\n\u001b[32m   1342\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1345\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1346\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(client_response)\n\u001b[32m   1348\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response.headers, [client_response.text])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:203\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    200\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.raise_error_async(status_code, response_json, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:225\u001b[39m, in \u001b[36mAPIError.raise_error_async\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    212\u001b[39m \n\u001b[32m    213\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    222\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    227\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"What are the recent ways to evaluate agentic AI systems in finance? \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dee3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set logging to DEBUG to see the internal \"handshakes\" between agents\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad444c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"What are the recent ways to evaluate agentic AI systems in finance? \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31704d60",
   "metadata": {},
   "source": [
    "## Sequential Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b9943",
   "metadata": {},
   "source": [
    "**Best practices **\n",
    "\n",
    "- **Use placeholders**: `{topic}`, `{journal_guidelines}` in the instruction.\n",
    "Pass concrete values in the inputs to the runner / Crew kickoff.\n",
    "- Include a short, explicit checklist of journal constraints in `{journal_guidelines}` (word limits, section order, citation style, figure/table rules).\n",
    "- Keep `temperature` low for deterministic outlines (e.g., 0‚Äì0.3).\n",
    "- Validate the returned outline against the checklist and loop if missing constraints.\n",
    "- Use `Process.sequential` / rate-limit handling as you already do with retry_config.\n",
    "\n",
    "*Use a template (placeholders) in the agent instruction and pass the concrete values (topic, journal guidelines) via the runner / kickoff inputs. \n",
    "This keeps the agent prompt generic and lets you reuse it across topics and journals.*\n",
    "\n",
    "\n",
    "**Centralized model + factory for multi-agent systems**\n",
    "\n",
    "When defining multiple agents that use the same LLM (e.g., Gemini), use a central constant or small factory so you don't repeat literals ‚Äî and prefer a factory (make_gemini) so you can easily vary `model`, `temperature`, or `retry options` per agent. \n",
    "\n",
    "*Avoid sharing the same live LLM instance if the SDK docs warn of internal state ‚Äî use the factory to create instances.*\n",
    "\n",
    "\n",
    "- Single SOURCE OF TRUTH for model name & retry config.\n",
    "- Factory = easy per-agent overrides (critique vs drafting).\n",
    "- Centralize deterministic settings (temperature, max_tokens) in one place.\n",
    "- Avoid repeating code and typos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97948c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=\n",
    "journal_guidelines= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b09f279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PlanningAgent created.\n",
      "‚úÖ ResearchAgent created.\n",
      "‚úÖ WriterAgent created.\n",
      "‚úÖ EditorAgent created.\n",
      "‚úÖ Sequential Agent created.\n"
     ]
    }
   ],
   "source": [
    "# Centralized model config + factory\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "def make_gemini(model_name: str = MODEL_NAME, retry_options = retry_config):\n",
    "    # return a fresh Gemini instance so each agent can have its own instance if needed\n",
    "    return Gemini(model=model_name, retry_options=retry_options)\n",
    "\n",
    "# default instance (or call make_gemini() per-agent)\n",
    "GEMINI_DEFAULT = make_gemini()\n",
    "# use GEMINI_DEFAULT instead of repeating Gemini(...)\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "planning_agent = Agent(\n",
    "    name=\"PlanningAgent\",\n",
    "    model=GEMINI_DEFAULT,\n",
    "    instruction=\"\"\"Create an outline for an academic paper on a given topic as an integrative literature review.\n",
    "Requirements:\n",
    "- Provide a catchy title\n",
    "- A short abstract (50-100 words)\n",
    "- 5 keywords\n",
    "- 3‚Äì5 main sections (e.g., Introduction, Methodology, Results/Discussion), each with bullet points of content\n",
    "- A concluding thought suggesting an initial search query\n",
    "- Apply formatting rules as specified in the provided editorial guidelines \n",
    "\"\"\",\n",
    "    output_key=\"paper_outline\",\n",
    ")\n",
    "print(\"‚úÖ PlanningAgent created.\")\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "research_agent = Agent(\n",
    "    name=\"ResearchAgent\",\n",
    "    model=GEMINI_DEFAULT,\n",
    "    instruction=\"\"\"Use google_search tool to find relevant papers on Google Scholar\n",
    "    Requirements:\n",
    "    - Papers should be published within the last 2 years\n",
    "    - Be in English\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"research_findings\",\n",
    ")\n",
    "print(\"‚úÖ ResearchAgent created.\")\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "# Writer Agent: Writes the full blog post based on the outline from the previous agent.\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    model=GEMINI_DEFAULT,\n",
    "    # The `{paper_outline}` and {research_findings} placeholders automatically inject the state value from the previous agent's output.\n",
    "    instruction=\"\"\"Following this outline strictly: {paper_outline}\n",
    "    Use {research_findings}\n",
    "    Write a brief, 200-word  research proposal\"\"\",\n",
    "    output_key=\"paper_draft\",  # The result of this agent will be stored with this key.\n",
    ")\n",
    "print(\"‚úÖ WriterAgent created.\")\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "# Editor Agent: Edits and polishes the draft from the writer agent.\n",
    "editor_agent = Agent(\n",
    "    name=\"EditorAgent\",\n",
    "    model=GEMINI_DEFAULT,\n",
    "    # This agent receives the `{blog_draft}` from the writer agent's output.\n",
    "    instruction=\"\"\"Edit this draft: {paper_draft}\n",
    "    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n",
    "    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ EditorAgent created.\")\n",
    "#------------------\n",
    "\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"PaperPipeline\",\n",
    "    sub_agents=[planning_agent, research_agent, writer_agent, editor_agent],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Sequential Agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb9d78df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Create an outline for an academic paper on a given topic as an integrative literature review.\n",
      "Requirements:\n",
      "- Provide a catchy title\n",
      "- A short abstract (50-100 words)\n",
      "- 5 keywords\n",
      "- 3‚Äì5 main sections (e.g., Introduction, Methodology, Results/Discussion), each with bullet points of content\n",
      "- A concluding thought suggesting an initial search query\n",
      "- Apply formatting rules as specified in the provided editorial guidelines \n",
      "\n",
      "\n",
      "You are an agent. Your internal name is \"PlanningAgent\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Write a research brief about AI uses in Finance, abstract should be less than 150 words\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Write a research brief about AI uses in Finance, abstract should be less than 150 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x17fbada60>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x1370499d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x308d4e540>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 07:59:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=28'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m runner = InMemoryRunner(agent=root_agent)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m runner.run_debug(\u001b[33m\"\u001b[39m\u001b[33mWrite a research brief about AI uses in Finance, abstract should be less than 150 words\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:1168\u001b[39m, in \u001b[36mRunner.run_debug\u001b[39m\u001b[34m(self, user_messages, user_id, session_id, run_config, quiet, verbose)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1166\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUser > \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_async(\n\u001b[32m   1169\u001b[39m     user_id=user_id,\n\u001b[32m   1170\u001b[39m     session_id=session.id,\n\u001b[32m   1171\u001b[39m     new_message=types.UserContent(parts=[types.Part(text=message)]),\n\u001b[32m   1172\u001b[39m     run_config=run_config,\n\u001b[32m   1173\u001b[39m ):\n\u001b[32m   1174\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet:\n\u001b[32m   1175\u001b[39m     print_event(event, verbose=verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:505\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    500\u001b[39m       \u001b[38;5;28;01mawait\u001b[39;00m _run_compaction_for_sliding_window(\n\u001b[32m    501\u001b[39m           \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    502\u001b[39m       )\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:493\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    486\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    487\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m     )\n\u001b[32m    492\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    495\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;66;03m# the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:722\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    719\u001b[39m is_transcribing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m722\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_live_call:\n\u001b[32m    724\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m event.partial \u001b[38;5;129;01mand\u001b[39;00m _is_transcription(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/runners.py:482\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    481\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    483\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py:77\u001b[39m, in \u001b[36mSequentialAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_agent_state_event(ctx)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(sub_agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ctx.should_pause_invocation(event):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/agents/llm_agent.py:460\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    458\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:370\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    368\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    371\u001b[39m     last_event = event\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:447\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    436\u001b[39m model_response_event = Event(\n\u001b[32m    437\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    438\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    439\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    440\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    441\u001b[39m )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    443\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    444\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    445\u001b[39m     )\n\u001b[32m    446\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    451\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m         )\n\u001b[32m    456\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    457\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    458\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:816\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    813\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m816\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    817\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:800\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    787\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    788\u001b[39m     llm_request,\n\u001b[32m    789\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    790\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    791\u001b[39m )\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    793\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    794\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     )\n\u001b[32m    799\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    801\u001b[39m     trace_call_llm(\n\u001b[32m    802\u001b[39m         invocation_context,\n\u001b[32m    803\u001b[39m         model_response_event.id,\n\u001b[32m    804\u001b[39m         llm_request,\n\u001b[32m    805\u001b[39m         llm_response,\n\u001b[32m    806\u001b[39m     )\n\u001b[32m    807\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1053\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1051\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m error_response\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m model_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:1039\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m   1040\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py:262\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ce.code == \u001b[32m429\u001b[39m:\n\u001b[32m    257\u001b[39m   \u001b[38;5;66;03m# We expect running into a Resource Exhausted error to be a common\u001b[39;00m\n\u001b[32m    258\u001b[39m   \u001b[38;5;66;03m# client error that developers would run into. We enhance the messaging\u001b[39;00m\n\u001b[32m    259\u001b[39m   \u001b[38;5;66;03m# with possible fixes to this issue.\u001b[39;00m\n\u001b[32m    260\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m _ResourceExhaustedError(ce) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mce\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ce\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py:241\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m close_result\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    242\u001b[39m       model=llm_request.model,\n\u001b[32m    243\u001b[39m       contents=llm_request.contents,\n\u001b[32m    244\u001b[39m       config=llm_request.config,\n\u001b[32m    245\u001b[39m   )\n\u001b[32m    246\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    247\u001b[39m   logger.debug(_build_response_log(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:7018\u001b[39m, in \u001b[36mgenerate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   7016\u001b[39m original_tools_length = \u001b[32m0\u001b[39m\n\u001b[32m   7017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, types.GenerateContentConfig):\n\u001b[32m-> \u001b[39m\u001b[32m7018\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m config.tools:\n\u001b[32m   7019\u001b[39m     original_tools_length = \u001b[38;5;28mlen\u001b[39m(config.tools)\n\u001b[32m   7020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:5824\u001b[39m, in \u001b[36m_generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5822\u001b[39m   if request_url_dict:\n\u001b[32m   5823\u001b[39m     path = '{model}:generateContent'.format_map(request_url_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5824\u001b[39m   else:\n\u001b[32m   5825\u001b[39m     path = '{model}:generateContent'\n\u001b[32m   5826\u001b[39m else:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1434\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1425\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1429\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1430\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1431\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1432\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1435\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1436\u001b[39m   )\n\u001b[32m   1437\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1438\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1367\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1365\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1368\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1369\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1347\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1339\u001b[39m   \u001b[38;5;66;03m# aiohttp is not available. Fall back to httpx.\u001b[39;00m\n\u001b[32m   1340\u001b[39m   client_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_httpx_client.request(\n\u001b[32m   1341\u001b[39m       method=http_request.method,\n\u001b[32m   1342\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1345\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1346\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(client_response)\n\u001b[32m   1348\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response.headers, [client_response.text])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:203\u001b[39m, in \u001b[36mAPIError.raise_for_async_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    200\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnsupported response type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.raise_error_async(status_code, response_json, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:225\u001b[39m, in \u001b[36mAPIError.raise_error_async\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    212\u001b[39m \n\u001b[32m    213\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    222\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    227\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\"Write a research brief about AI uses in Finance, abstract should be less than 150 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f0a93",
   "metadata": {},
   "source": [
    "Rate Limits:\n",
    "\n",
    "Use Process.sequential instead of Process.hierarchical. This ensures only one agent calls the API at a time, keeping you under the 10-15 RPM (Requests Per Minute) limit.\n",
    "\n",
    "Model Choice:\n",
    "\n",
    "Use Gemini 2.0 Flash. It is significantly faster and has a higher daily request quota ($1,000$ RPD) than the \"Pro\" models ($100$ RPD).\n",
    "\n",
    "Memory:\n",
    "\n",
    "If your research is long, use the full_context=True parameter in CrewAI. Since Gemini has a 1M+ token window, you don't need to worry about the agents \"forgetting\" the start of the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc7bfd",
   "metadata": {},
   "source": [
    "## Parallel Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "171aca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ tech_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Tech Researcher: Focuses on AI and ML trends.\n",
    "tech_researcher = Agent(\n",
    "    name=\"TechResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\n",
    "the main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ tech_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0bd8be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ health_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Health Researcher: Focuses on medical breakthroughs.\n",
    "health_researcher = Agent(\n",
    "    name=\"HealthResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\n",
    "their practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"health_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ health_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41b15d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ finance_researcher created.\n"
     ]
    }
   ],
   "source": [
    "# Finance Researcher: Focuses on fintech trends.\n",
    "finance_researcher = Agent(\n",
    "    name=\"FinanceResearcher\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\n",
    "their market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"finance_research\",  # The result will be stored with this key.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ finance_researcher created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed4499dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ aggregator_agent created.\n"
     ]
    }
   ],
   "source": [
    "# The AggregatorAgent runs *after* the parallel step to synthesize the results.\n",
    "aggregator_agent = Agent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n",
    "    instruction=\"\"\"Combine these three research findings into a single executive summary:\n",
    "\n",
    "    **Technology Trends:**\n",
    "    {tech_research}\n",
    "    \n",
    "    **Health Breakthroughs:**\n",
    "    {health_research}\n",
    "    \n",
    "    **Finance Innovations:**\n",
    "    {finance_research}\n",
    "    \n",
    "    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n",
    "    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ aggregator_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "151b7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ aggregator_agent created.\n"
     ]
    }
   ],
   "source": [
    "# The AggregatorAgent runs *after* the parallel step to synthesize the results.\n",
    "aggregator_agent = Agent(\n",
    "    name=\"AggregatorAgent\",\n",
    "    model=Gemini(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        retry_options=retry_config\n",
    "    ),\n",
    "    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n",
    "    instruction=\"\"\"Combine these three research findings into a single executive summary:\n",
    "\n",
    "    **Technology Trends:**\n",
    "    {tech_research}\n",
    "    \n",
    "    **Health Breakthroughs:**\n",
    "    {health_research}\n",
    "    \n",
    "    **Finance Innovations:**\n",
    "    {finance_research}\n",
    "    \n",
    "    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n",
    "    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n",
    ")\n",
    "\n",
    "print(\"‚úÖ aggregator_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "80bd84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parallel and Sequential Agents created.\n"
     ]
    }
   ],
   "source": [
    "# The ParallelAgent runs all its sub-agents simultaneously.\n",
    "parallel_research_team = ParallelAgent(\n",
    "    name=\"ParallelResearchTeam\",\n",
    "    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n",
    ")\n",
    "\n",
    "# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\n",
    "root_agent = SequentialAgent(\n",
    "    name=\"ResearchSystem\",\n",
    "    sub_agents=[parallel_research_team, aggregator_agent],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Parallel and Sequential Agents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "67800cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research the latest AI/ML trends. Include 3 key developments,\n",
      "the main companies involved, and the potential impact. Keep the report very concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"TechResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research recent medical breakthroughs. Include 3 significant advances,\n",
      "their practical applications, and estimated timelines. Keep the report concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"HealthResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research current fintech trends. Include 3 key trends,\n",
      "their market implications, and the future outlook. Keep the report concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"FinanceResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Run the daily executive briefing on Tech, Health, and Finance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ac74e30>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae7c9d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae354c0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae5d4d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ac74740>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae040d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae35550>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae4f590>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae4e5a0>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 10:14:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=23'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 10:14:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=29'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.failed exception=CancelledError()\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/6f/cqjqnsbj3pgb13mm94xj221wssky6y/T/ipykernel_76107/2725895140.py\", line 2, in <module>\n",
      "  |     response = await runner.run_debug(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 1168, in run_debug\n",
      "  |     async for event in self.run_async(\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 505, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 493, in _run_with_trace\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 722, in _exec_with_plugin\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 482, in execute\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py\", line 77, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 192, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 71, in _merge_agent_run\n",
      "  |     async with asyncio.TaskGroup() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/taskgroups.py\", line 71, in __aexit__\n",
      "  |     return await self._aexit(et, exc)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/taskgroups.py\", line 164, in _aexit\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 62, in process_an_agent\n",
      "    |     async for event in events_for_one_agent:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/llm_agent.py\", line 460, in _run_async_impl\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 370, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 447, in _run_one_step_async\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 816, in _call_llm_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 800, in _call_llm_with_tracing\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1053, in _run_and_handle_error\n",
      "    |     raise model_error\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1039, in _run_and_handle_error\n",
      "    |     async for response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 262, in generate_content_async\n",
      "    |     raise ce\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 241, in generate_content_async\n",
      "    |     response = await self.api_client.aio.models.generate_content(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 7018, in generate_content\n",
      "    |     if config.tools:\n",
      "    |              ^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 5824, in _generate_content\n",
      "    |     else:\n",
      "    |           \n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1434, in async_request\n",
      "    |     result = await self._async_request(\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1367, in _async_request\n",
      "    |     return await self._async_retry(  # type: ignore[no-any-return]\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1347, in _async_request_once\n",
      "    |     await errors.APIError.raise_for_async_response(client_response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 203, in raise_for_async_response\n",
      "    |     await cls.raise_error_async(status_code, response_json, response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 225, in raise_error_async\n",
      "    |     raise ClientError(status_code, response_json, response)\n",
      "    | google.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\n",
      "    +---------------- 2 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 62, in process_an_agent\n",
      "    |     async for event in events_for_one_agent:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/llm_agent.py\", line 460, in _run_async_impl\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 370, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 447, in _run_one_step_async\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 816, in _call_llm_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 800, in _call_llm_with_tracing\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1053, in _run_and_handle_error\n",
      "    |     raise model_error\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1039, in _run_and_handle_error\n",
      "    |     async for response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 262, in generate_content_async\n",
      "    |     raise ce\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 241, in generate_content_async\n",
      "    |     response = await self.api_client.aio.models.generate_content(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 7018, in generate_content\n",
      "    |     if config.tools:\n",
      "    |              ^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 5824, in _generate_content\n",
      "    |     else:\n",
      "    |           \n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1434, in async_request\n",
      "    |     result = await self._async_request(\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1367, in _async_request\n",
      "    |     return await self._async_retry(  # type: ignore[no-any-return]\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1347, in _async_request_once\n",
      "    |     await errors.APIError.raise_for_async_response(client_response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 203, in raise_for_async_response\n",
      "    |     await cls.raise_error_async(status_code, response_json, response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 225, in raise_error_async\n",
      "    |     raise ClientError(status_code, response_json, response)\n",
      "    | google.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\n",
      "    +------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Run the daily executive briefing on Tech, Health, and Finance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4c2ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research the latest AI/ML trends. Include 3 key developments,\n",
      "the main companies involved, and the potential impact. Keep the report very concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"TechResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:close.started\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research recent medical breakthroughs. Include 3 significant advances,\n",
      "their practical applications, and estimated timelines. Keep the report concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"HealthResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "DEBUG:google_adk.google.adk.models.google_llm:\n",
      "LLM Request:\n",
      "-----------------------------------------------------------\n",
      "System Instruction:\n",
      "Research current fintech trends. Include 3 key trends,\n",
      "their market implications, and the future outlook. Keep the report concise (100 words).\n",
      "\n",
      "You are an agent. Your internal name is \"FinanceResearcher\".\n",
      "-----------------------------------------------------------\n",
      "Config:\n",
      "{'http_options': {'headers': {'x-goog-api-client': 'google-adk/1.21.0 gl-python/3.12.11', 'user-agent': 'google-adk/1.21.0 gl-python/3.12.11'}}}\n",
      "-----------------------------------------------------------\n",
      "Contents:\n",
      "{\"parts\":[{\"text\":\"Run the daily executive briefing on Tech, Health, and Finance\"}],\"role\":\"user\"}\n",
      "-----------------------------------------------------------\n",
      "Functions:\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: debug_session_id\n",
      "\n",
      "User > Run the daily executive briefing on Tech, Health, and Finance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae524b0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae7c9d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae4dd90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae5d4d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae52e10>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x30ae040d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae45dc0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae45ee0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x30ae34560>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 10:15:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=24'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 10:15:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=22'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 10:15:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=28'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.failed exception=CancelledError()\n",
      "DEBUG:httpcore.http11:response_closed.failed exception=CancelledError()\n",
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/6f/cqjqnsbj3pgb13mm94xj221wssky6y/T/ipykernel_76107/2725895140.py\", line 2, in <module>\n",
      "  |     response = await runner.run_debug(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 1168, in run_debug\n",
      "  |     async for event in self.run_async(\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 505, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 493, in _run_with_trace\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 722, in _exec_with_plugin\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/runners.py\", line 482, in execute\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py\", line 77, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 192, in _run_async_impl\n",
      "  |     async for event in agen:\n",
      "  |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 71, in _merge_agent_run\n",
      "  |     async with asyncio.TaskGroup() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/taskgroups.py\", line 71, in __aexit__\n",
      "  |     return await self._aexit(et, exc)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/taskgroups.py\", line 164, in _aexit\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/parallel_agent.py\", line 62, in process_an_agent\n",
      "    |     async for event in events_for_one_agent:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py\", line 294, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/agents/llm_agent.py\", line 460, in _run_async_impl\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 370, in run_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 447, in _run_one_step_async\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 816, in _call_llm_async\n",
      "    |     async for event in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 800, in _call_llm_with_tracing\n",
      "    |     async for llm_response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1053, in _run_and_handle_error\n",
      "    |     raise model_error\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 1039, in _run_and_handle_error\n",
      "    |     async for response in agen:\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 262, in generate_content_async\n",
      "    |     raise ce\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/adk/models/google_llm.py\", line 241, in generate_content_async\n",
      "    |     response = await self.api_client.aio.models.generate_content(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 7018, in generate_content\n",
      "    |     if config.tools:\n",
      "    |              ^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/models.py\", line 5824, in _generate_content\n",
      "    |     else:\n",
      "    |           \n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1434, in async_request\n",
      "    |     result = await self._async_request(\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1367, in _async_request\n",
      "    |     return await self._async_retry(  # type: ignore[no-any-return]\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    |     do = await self.iter(retry_state=retry_state)\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    |     result = await action(retry_state)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    |     return call(*args, **kwargs)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 400, in <lambda>\n",
      "    |     self._add_action_func(lambda rs: rs.outcome.result())\n",
      "    |                                      ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    |     return self.__get_result()\n",
      "    |            ^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    |     raise self._exception\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    |     result = await fn(*args, **kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py\", line 1347, in _async_request_once\n",
      "    |     await errors.APIError.raise_for_async_response(client_response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 203, in raise_for_async_response\n",
      "    |     await cls.raise_error_async(status_code, response_json, response)\n",
      "    |   File \"/Users/e5028514/code/.venv/lib/python3.12/site-packages/google/genai/errors.py\", line 225, in raise_error_async\n",
      "    |     raise ClientError(status_code, response_json, response)\n",
      "    | google.genai.errors.ClientError: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\n",
      "    +------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    }
   ],
   "source": [
    "runner = InMemoryRunner(agent=root_agent)\n",
    "response = await runner.run_debug(\n",
    "    \"Run the daily executive briefing on Tech, Health, and Finance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e432f78",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Demo project: \"Research Lab\" Multi-Agent App\n",
    "\n",
    "**Scenario**\n",
    "\n",
    "For research and paper writing, a multi-agent system is far superior to a single AI because it mimics the **peer-review and editorial process**. Instead of one AI \"guessing\" the whole paper, you have specialized agents that fact-check, critique, and refine each other's work.\n",
    "\n",
    "\n",
    "### The Agent Lineup \n",
    "\n",
    " **The Librarian (Discovery Agent)**\n",
    "\n",
    "* **Specialty:** Semantic search and source vetting.\n",
    "* **Task:** Uses tools like ArXiv, Semantic Scholar, or Elicit APIs to find the top 10 most relevant papers. It doesn't just look for keywords; it looks for \"methodological fit.\"\n",
    "* **Output:** A curated list of PDFs and a \"Relevance Score\" for each.\n",
    "\n",
    "**The Analyst (Extraction Agent)**\n",
    "\n",
    "* **Specialty:** Data and Method synthesis.\n",
    "* **Task:** Reads the papers found by the Librarian. It extracts specific data points, formulas, and limitations into a structured table.\n",
    "* **Output:** A synthesis matrix (e.g., \"Paper A used  method but had  sample size\").\n",
    "\n",
    "**The Ghostwriter (Drafting Agent)**\n",
    "\n",
    "* **Specialty:** Academic tone and structure.\n",
    "* **Task:** Takes the synthesis matrix and the user‚Äôs notes to draft specific sections (Introduction, Literature Review). It focuses on flow and logical transitions.\n",
    "* **Output:** A rough Markdown draft.\n",
    "\n",
    "**The Peer Reviewer (Critique Agent)**\n",
    "\n",
    "* **Specialty:** Logical fallacies and \"Red Teaming.\"\n",
    "* **Task:** This agent is programmed to be **skeptical**. It looks at the Ghostwriter's draft and says: *\"You claimed X, but the Analyst's data actually suggests Y. Also, your citation for Z is missing.\"*\n",
    "* **Output:** A list of \"Required Revisions.\"\n",
    "\n",
    "---\n",
    "\n",
    "### The Multi-Agent Workflow\n",
    "\n",
    "In a single-agent app, you get one response. In this multi-agent app, the \"magic\" happens in the **loop**:\n",
    "\n",
    "1. **Phase 1:** Librarian gathers  Analyst processes.\n",
    "2. **Phase 2:** Ghostwriter drafts Section 1.\n",
    "3. **Phase 3:** Peer Reviewer critiques Section 1.\n",
    "4. **Phase 4:** If Peer Reviewer is unhappy, Ghostwriter **must** rewrite.\n",
    "5. **Phase 5:** Final Polish agent ensures APA/MLA formatting and checks for \"AI-style\" repetitive phrasing.\n",
    "\n",
    "\n",
    "**Benefits Over Single-Agent Systems**\n",
    "\n",
    "| Feature | Single Agent (Standard Chat) | Multi-Agent \"Research Lab\" |\n",
    "| --- | --- | --- |\n",
    "| **Hallucinations** | High (often makes up citations). | Low (The Librarian provides the only \"truth\" the Writer can use). |\n",
    "| **Tone** | Often \"flowery\" or generic. | Controlled by the \"Style Enforcer\" agent. |\n",
    "| **Rigorousness** | Accepts its own first draft. | Forces internal \"debate\" before the user even sees it. |\n",
    "\n",
    "---\n",
    "\n",
    "**App Idea: \"Manuscript Flow\"**\n",
    "\n",
    "A specialized workspace where your \"Agents\" live in a sidebar. You see a live \"Activity Feed\" of them talking to each other:\n",
    "\n",
    "* *Librarian:* \"Found a conflict in the data for the 2022 study.\"\n",
    "* *Reviewer:* \"Ghostwriter, please address this conflict in Paragraph 3.\"\n",
    "* *Ghostwriter:* \"Updating now...\"\n",
    "\n",
    "We will use CrewAI for this project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262f649c",
   "metadata": {},
   "source": [
    "To build a multi-agent research app using only the **Google Generative AI SDK** (no CrewAI, LangGraph, etc.), you essentially need to manage a \"State Machine\" manually.\n",
    "\n",
    "On the **Gemini Free Tier (2026)**, your best strategy is to use **Gemini 2.0 Flash** for most tasks because it offers a higher rate limit ( requests per day) compared to the Pro models, which are often restricted or removed from the free tier.\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 1: The Orchestration Logic\n",
    "\n",
    "Since you aren't using a framework, you must write a Python \"Controller\" that passes data between agents. Each \"Agent\" is actually just a specific **System Instruction** paired with a Gemini model instance.\n",
    "\n",
    "### Step-by-Step Architecture:\n",
    "\n",
    "1. **Define Agent \"Personas\":** Create a dictionary of system prompts (Librarian, Writer, Reviewer).\n",
    "2. **State Management:** Use a simple Python dictionary to hold the \"Paper State\" (e.g., `current_draft`, `sources`, `critiques`).\n",
    "3. **The Loop:** * Call **Agent A** (Librarian)  Save result to State.\n",
    "* Pass State to **Agent B** (Writer)  Save draft to State.\n",
    "* Pass State to **Agent C** (Reviewer)  Get feedback.\n",
    "* If \"Reviewer\" flags errors, loop back to the Writer.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 2: Coding the Agents (Python ADK)\n",
    "\n",
    "You will use the `google-generativeai` library. For the Free Tier, ensure you handle **Rate Limiting** by adding `time.sleep()` between calls if you hit 429 errors.\n",
    "\n",
    "```python\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# 1. Setup\n",
    "genai.configure(api_key=\"YOUR_FREE_TIER_KEY\")\n",
    "\n",
    "# 2. Define the Agent Factories\n",
    "def call_agent(role_instruction, user_input):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        system_instruction=role_instruction\n",
    "    )\n",
    "    response = model.generate_content(user_input)\n",
    "    return response.text\n",
    "\n",
    "# 3. Specific Prompts\n",
    "LIBRARIAN_PROMPT = \"You are a research librarian. Extract key facts and citations from the provided text.\"\n",
    "WRITER_PROMPT = \"You are an academic writer. Use the facts provided to write a formal introduction.\"\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 3: Implementing \"Grounding\"\n",
    "\n",
    "A research app is useless if it hallucinates. Since you are on the Free Tier, you can use Gemini's **Built-in Google Search Tool** (Grounding). This allows your \"Librarian\" agent to actually browse the web for real papers.\n",
    "\n",
    "```python\n",
    "# Enable Google Search for the Librarian\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(\n",
    "    contents=\"What are the latest breakthroughs in fusion energy?\",\n",
    "    tools=[{'google_search': {}}]\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 4: Managing Free Tier Constraints\n",
    "\n",
    "In 2026, the Gemini Free Tier has specific \"Token Buckets.\"\n",
    "\n",
    "* **Gemini 2.0 Flash:** ~10-15 Requests Per Minute (RPM).\n",
    "* **Context Window:** Use the **1M token window** to your advantage. Instead of many small calls, try to send the *entire* state of the research paper in one \"Reviewer\" call to save on your daily request quota (‚Äì RPD).\n",
    "\n",
    "---\n",
    "\n",
    "## Stage 5: User Interface (Streamlit)\n",
    "\n",
    "Since you want an \"app,\" the fastest way to wrap this Python logic without a heavy backend is **Streamlit**. It‚Äôs a single-file Python framework that creates a web UI for your agents.\n",
    "\n",
    "| Feature | implementation |\n",
    "| --- | --- |\n",
    "| **Input** | A text box for the \"Research Topic.\" |\n",
    "| **Live Logs** | Display which agent is currently \"thinking.\" |\n",
    "| **Download** | Export the final `paper_state[\"final_draft\"]` as a .docx or .txt file. |\n",
    "\n",
    "**Would you like me to write a complete \"Controller Loop\" script that handles the handoff between the Librarian and the Writer?**\n",
    "\n",
    "---\n",
    "\n",
    "[Building a Research AI Agent from Scratch](https://www.youtube.com/watch?v=f3KHI1dpc1Q)\n",
    "This video is highly relevant because it demonstrates how to build a multi-agent system from scratch using Python and Gemini without relying on complex orchestration frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf402c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in ./.venv/lib/python3.12/site-packages (4.1.3)\n",
      "Collecting protobuf<7.0.0,>=6.31.1\n",
      "  Downloading protobuf-6.33.3-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting google-auth<2.42.0,>=2.15.0\n",
      "  Using cached google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting opentelemetry-api>=1.35.0\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk<1.39.0,>=1.35.0\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: crewai[tools] in ./.venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth<2.42.0,>=2.15.0) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<2.42.0,>=2.15.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth<2.42.0,>=2.15.0) (4.9.1)\n",
      "Collecting opentelemetry-api>=1.35.0\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<1.39.0,>=1.35.0)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk<1.39.0,>=1.35.0) (4.15.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.35.0) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.35.0) (3.23.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<2.42.0,>=2.15.0) (0.6.1)\n",
      "Requirement already satisfied: aiosqlite~=0.21.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.21.0)\n",
      "Requirement already satisfied: appdirs~=1.4.4 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.4.4)\n",
      "Requirement already satisfied: chromadb~=1.1.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.1.1)\n",
      "Requirement already satisfied: click~=8.1.7 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (8.1.8)\n",
      "Requirement already satisfied: instructor>=1.3.3 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.12.0)\n",
      "Requirement already satisfied: json-repair~=0.25.2 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.25.3)\n",
      "Requirement already satisfied: json5~=0.10.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.10.0)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.1.0)\n",
      "Requirement already satisfied: mcp~=1.16.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.16.0)\n",
      "Requirement already satisfied: openai~=1.83.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.83.0)\n",
      "Requirement already satisfied: openpyxl~=3.1.5 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (3.1.5)\n",
      "INFO: pip is looking at multiple versions of crewai[tools] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting crewai[tools]\n",
      "  Downloading crewai-1.7.2-py3-none-any.whl.metadata (36 kB)\n",
      "  Downloading crewai-1.7.1-py3-none-any.whl.metadata (36 kB)\n",
      "  Downloading crewai-1.7.0-py3-none-any.whl.metadata (36 kB)\n",
      "  Downloading crewai-1.6.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting json-repair==0.25.2 (from crewai[tools])\n",
      "  Downloading json_repair-0.25.2-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.34.1)\n",
      "Requirement already satisfied: pdfplumber>=0.11.4 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.11.9)\n",
      "Requirement already satisfied: portalocker==2.7.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2.7.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.10.1 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2.10.1)\n",
      "Requirement already satisfied: pydantic>=2.11.9 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2.11.10)\n",
      "Requirement already satisfied: pyjwt>=2.9.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv>=1.1.1 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.1.1)\n",
      "Requirement already satisfied: regex>=2024.9.11 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers>=0.20.3 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.20.3)\n",
      "Requirement already satisfied: tomli-w>=1.1.0 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (1.1.0)\n",
      "Requirement already satisfied: tomli>=2.0.2 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (2.0.2)\n",
      "Requirement already satisfied: uv>=0.4.25 in ./.venv/lib/python3.12/site-packages (from crewai[tools]) (0.9.24)\n",
      "Collecting crewai-tools==1.6.1 (from crewai[tools])\n",
      "  Downloading crewai_tools-1.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting beautifulsoup4>=4.13.4 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting docker>=7.1.0 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting lancedb>=0.5.4 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading lancedb-0.26.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting pymupdf>=1.26.6 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Collecting python-docx>=1.2.0 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pytube>=15.0.0 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests>=2.32.5 in ./.venv/lib/python3.12/site-packages (from crewai-tools==1.6.1->crewai[tools]) (2.32.5)\n",
      "Collecting tiktoken>=0.8.0 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting youtube-transcript-api>=1.2.2 (from crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (1.4.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai[tools]) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (2.4.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (1.34.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in ./.venv/lib/python3.12/site-packages (from chromadb~=1.1.0->crewai[tools]) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai[tools]) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai[tools]) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai[tools]) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in ./.venv/lib/python3.12/site-packages (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai[tools]) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.5->crewai-tools==1.6.1->crewai[tools]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.5->crewai-tools==1.6.1->crewai[tools]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.5->crewai-tools==1.6.1->crewai[tools]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.5->crewai-tools==1.6.1->crewai[tools]) (2025.11.12)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.56.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.5 in ./.venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.7)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in ./.venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.0)\n",
      "INFO: pip is looking at multiple versions of google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-genai<2.0.0,>=1.56.0 (from langchain-google-genai)\n",
      "  Downloading google_genai-1.57.0-py3-none-any.whl.metadata (53 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-4.1.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-4.1.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_google_genai-4.1.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "INFO: pip is still looking at multiple versions of google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-genai<2.0.0,>=1.53.0 (from langchain-google-genai)\n",
      "  Downloading google_genai-1.55.0-py3-none-any.whl.metadata (47 kB)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./.venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.53.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb~=1.1.0->crewai[tools]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb~=1.1.0->crewai[tools]) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (25.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.5->langchain-google-genai) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.11.9->crewai[tools]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.11.9->crewai[tools]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.11.9->crewai[tools]) (0.4.2)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4>=4.13.4->crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb~=1.1.0->crewai[tools]) (1.2.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (3.13.3)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (5.6.3)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (3.1.6)\n",
      "Requirement already satisfied: jiter<0.11,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (0.10.0)\n",
      "Requirement already satisfied: pre-commit>=4.3.0 in ./.venv/lib/python3.12/site-packages (from instructor>=1.3.3->crewai[tools]) (4.5.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai[tools]) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai[tools]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai[tools]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai[tools]) (2.19.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb~=1.1.0->crewai[tools]) (1.5.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai[tools]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai[tools]) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai[tools]) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai[tools]) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai[tools]) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai[tools]) (0.10)\n",
      "Collecting deprecation (from lancedb>=0.5.4->crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyarrow>=16 in ./.venv/lib/python3.12/site-packages (from lancedb>=0.5.4->crewai-tools==1.6.1->crewai[tools]) (22.0.0)\n",
      "Collecting lance-namespace>=0.3.2 (from lancedb>=0.5.4->crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading lance_namespace-0.4.5-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting lance-namespace-urllib3-client==0.4.5 (from lance-namespace>=0.3.2->lancedb>=0.5.4->crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading lance_namespace_urllib3_client-0.4.5-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb~=1.1.0->crewai[tools]) (0.1.2)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in ./.venv/lib/python3.12/site-packages (from mcp~=1.16.0->crewai[tools]) (0.4.3)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in ./.venv/lib/python3.12/site-packages (from mcp~=1.16.0->crewai[tools]) (0.0.21)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in ./.venv/lib/python3.12/site-packages (from mcp~=1.16.0->crewai[tools]) (3.1.1)\n",
      "Requirement already satisfied: starlette>=0.27 in ./.venv/lib/python3.12/site-packages (from mcp~=1.16.0->crewai[tools]) (0.50.0)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai[tools]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai[tools]) (25.12.19)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai[tools]) (1.14.0)\n",
      "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.12/site-packages (from openpyxl~=3.1.5->crewai[tools]) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools]) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools]) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools]) (1.34.1)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb~=1.1.0->crewai[tools])\n",
      "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-http to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-http>=1.30.0 (from crewai[tools])\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.39.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in ./.venv/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai[tools]) (20251230)\n",
      "Requirement already satisfied: Pillow>=9.1 in ./.venv/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai[tools]) (12.0.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./.venv/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai[tools]) (5.3.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./.venv/lib/python3.12/site-packages (from pdfminer.six==20251230->pdfplumber>=0.11.4->crewai[tools]) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber>=0.11.4->crewai[tools]) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber>=0.11.4->crewai[tools]) (2.23)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in ./.venv/lib/python3.12/site-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (3.5.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in ./.venv/lib/python3.12/site-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (2.6.15)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in ./.venv/lib/python3.12/site-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (1.10.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in ./.venv/lib/python3.12/site-packages (from pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (20.36.1)\n",
      "Collecting lxml>=3.1.0 (from python-docx>=1.2.0->crewai-tools==1.6.1->crewai[tools])\n",
      "  Downloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.12/site-packages (from tokenizers>=0.20.3->crewai[tools]) (0.36.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai[tools]) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai[tools]) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.20.3->crewai[tools]) (1.2.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai[tools]) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai[tools]) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai[tools]) (1.1.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in ./.venv/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (0.4.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in ./.venv/lib/python3.12/site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai[tools]) (4.5.1)\n",
      "Collecting defusedxml<0.8.0,>=0.7.1 (from youtube-transcript-api>=1.2.2->crewai-tools==1.6.1->crewai[tools])\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai[tools]) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb~=1.1.0->crewai[tools]) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai[tools]) (1.3.0)\n",
      "Downloading protobuf-6.33.3-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Using cached google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading crewai-1.6.1-py3-none-any.whl (642 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m642.9/642.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading crewai_tools-1.6.1-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading json_repair-0.25.2-py3-none-any.whl (12 kB)\n",
      "Downloading langchain_google_genai-4.1.1-py3-none-any.whl (65 kB)\n",
      "Downloading google_genai-1.55.0-py3-none-any.whl (703 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m703.4/703.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading lancedb-0.26.1-cp39-abi3-macosx_11_0_arm64.whl (43.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lance_namespace-0.4.5-py3-none-any.whl (11 kB)\n",
      "Downloading lance_namespace_urllib3_client-0.4.5-py3-none-any.whl (277 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading pymupdf-1.26.7-cp310-abi3-macosx_11_0_arm64.whl (22.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (994 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: soupsieve, pytube, pymupdf, protobuf, lxml, json-repair, deprecation, defusedxml, youtube-transcript-api, tiktoken, python-docx, opentelemetry-proto, opentelemetry-api, google-auth, docker, beautifulsoup4, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, lance-namespace-urllib3-client, opentelemetry-sdk, lance-namespace, google-genai, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-google-genai, lancedb, crewai, crewai-tools\n",
      "\u001b[2K  Attempting uninstall: protobuf‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 2/28\u001b[0m [pymupdf]\n",
      "\u001b[2K    Found existing installation: protobuf 5.29.5‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 2/28\u001b[0m [pymupdf]\n",
      "\u001b[2K    Uninstalling protobuf-5.29.5:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 2/28\u001b[0m [pymupdf]\n",
      "\u001b[2K      Successfully uninstalled protobuf-5.29.5‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 2/28\u001b[0m [pymupdf]\n",
      "\u001b[2K  Attempting uninstall: json-repair‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/28\u001b[0m [lxml]buf]\n",
      "\u001b[2K    Found existing installation: json_repair 0.25.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/28\u001b[0m [lxml]\n",
      "\u001b[2K    Uninstalling json_repair-0.25.3:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/28\u001b[0m [lxml]\n",
      "\u001b[2K      Successfully uninstalled json_repair-0.25.3‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 4/28\u001b[0m [lxml]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-proto‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10/28\u001b[0m [python-docx]\n",
      "\u001b[2K    Found existing installation: opentelemetry-proto 1.34.1‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10/28\u001b[0m [python-docx]\n",
      "\u001b[2K    Uninstalling opentelemetry-proto-1.34.1:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10/28\u001b[0m [python-docx]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-proto-1.34.1‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10/28\u001b[0m [python-docx]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-apim‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/28\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Found existing installation: opentelemetry-api 1.34.1‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/28\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K    Uninstalling opentelemetry-api-1.34.1:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/28\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-api-1.34.1‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/28\u001b[0m [opentelemetry-proto]\n",
      "\u001b[2K  Attempting uninstall: google-auth\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/28\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Found existing installation: google-auth 2.47.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/28\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K    Uninstalling google-auth-2.47.0:[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/28\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K      Successfully uninstalled google-auth-2.47.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12/28\u001b[0m [opentelemetry-api]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/28\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.55b1/28\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.55b1:‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15/28\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.55b115/28\u001b[0m [beautifulsoup4]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-common \u001b[32m16/28\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.34.1ntelemetry-semantic-conventions]\n",
      "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-common-1.34.1:m16/28\u001b[0m [opentelemetry-semantic-conventions]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.34.1pentelemetry-semantic-conventions]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-sdk‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/28\u001b[0m [lance-namespace-urllib3-client]\n",
      "\u001b[2K    Found existing installation: opentelemetry-sdk 1.34.1‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/28\u001b[0m [lance-namespace-urllib3-client]\n",
      "\u001b[2K    Uninstalling opentelemetry-sdk-1.34.1:\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/28\u001b[0m [lance-namespace-urllib3-client]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.34.1‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/28\u001b[0m [lance-namespace-urllib3-client]\n",
      "\u001b[2K  Attempting uninstall: google-genai[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/28\u001b[0m [opentelemetry-sdk]client]\n",
      "\u001b[2K    Found existing installation: google-genai 1.56.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/28\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K    Uninstalling google-genai-1.56.0:90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/28\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K      Successfully uninstalled google-genai-1.56.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/28\u001b[0m [opentelemetry-sdk]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-http‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21/28\u001b[0m [google-genai]]\n",
      "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.34.1[0m [google-genai]\n",
      "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-http-1.34.1:[0m \u001b[32m21/28\u001b[0m [google-genai]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.34.18\u001b[0m [google-genai]\n",
      "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-grpc\u001b[0m \u001b[32m21/28\u001b[0m [google-genai]\n",
      "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-grpc 1.34.1[0m [google-genai]\n",
      "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-grpc-1.34.1:[0m \u001b[32m21/28\u001b[0m [google-genai]\n",
      "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-grpc-1.34.18\u001b[0m [google-genai]\n",
      "\u001b[2K  Attempting uninstall: langchain-google-genai\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23/28\u001b[0m [opentelemetry-exporter-otlp-proto-grpc]\n",
      "\u001b[2K    Found existing installation: langchain-google-genai 4.1.3m23/28\u001b[0m [opentelemetry-exporter-otlp-proto-grpc]\n",
      "\u001b[2K    Uninstalling langchain-google-genai-4.1.3:m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23/28\u001b[0m [opentelemetry-exporter-otlp-proto-grpc]\n",
      "\u001b[2K      Successfully uninstalled langchain-google-genai-4.1.332m23/28\u001b[0m [opentelemetry-exporter-otlp-proto-grpc]\n",
      "\u001b[2K  Attempting uninstall: crewai‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m25/28\u001b[0m [lancedb]n-google-genai]c]\n",
      "\u001b[2K    Found existing installation: crewai 1.8.091m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m25/28\u001b[0m [lancedb]\n",
      "\u001b[2K    Uninstalling crewai-1.8.0:‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m26/28\u001b[0m [crewai]\n",
      "\u001b[2K      Successfully uninstalled crewai-1.8.00m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m26/28\u001b[0m [crewai]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m28/28\u001b[0m [crewai-tools][0m [crewai-tools]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
      "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
      "google-cloud-aiplatform 1.132.0 requires google-auth<3.0.0,>=2.45.0, but you have google-auth 2.41.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed beautifulsoup4-4.14.3 crewai-1.6.1 crewai-tools-1.6.1 defusedxml-0.7.1 deprecation-2.1.0 docker-7.1.0 google-auth-2.41.1 google-genai-1.55.0 json-repair-0.25.2 lance-namespace-0.4.5 lance-namespace-urllib3-client-0.4.5 lancedb-0.26.1 langchain-google-genai-4.1.1 lxml-6.0.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 protobuf-6.33.3 pymupdf-1.26.7 python-docx-1.2.0 pytube-15.0.0 soupsieve-2.8.1 tiktoken-0.12.0 youtube-transcript-api-1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install \"crewai[tools]\" \"langchain-google-genai\" \\\n",
    "  \"protobuf>=6.31.1,<7.0.0\" \\\n",
    "  \"google-auth<2.42.0,>=2.15.0\" \\\n",
    "  \"opentelemetry-api>=1.35.0\" \\\n",
    "  \"opentelemetry-sdk>=1.35.0,<1.39.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f222e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# run in google colab\n",
    "from google.colab import userdata\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8577431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in vs code\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise RuntimeError(\"missing key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57ce223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Gemini Model (Flash is better for Free Tier speed/limits)\n",
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    verbose=True, \n",
    "    temperature=0.5\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179ff807",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "799f456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16963c5c0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x16a67d4d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16963cb30>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 10:17:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=13126'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16963eb40>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x13709acd0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16963e180>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 10:18:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=9072'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The period spanning 2023 to 2026 has profoundly reshaped global finance, driven by a complex interplay of macroeconomic re-calibration, accelerated technological integration, persistent geopolitical fragmentation, and a maturing sustainable investment agenda. By 2026, the financial system operates under a new paradigm defined by elevated capital costs and a fundamental re-evaluation of asset valuations. The 'higher-for-longer' interest rate environment, established through sustained central bank tightening, necessitated a re-pricing across equity, fixed income, and real estate, shifting focus towards corporate resilience, debt servicing capacity, and free cash flow generation in a less accommodative economic climate.\n",
      "\n",
      "Technologically, Artificial Intelligence (AI) became an indispensable operational and strategic tool across all financial services, from advanced algorithmic trading and real-time risk management to hyper-personalized wealth advisory. This pervasive integration delivered significant competitive advantages in efficiency and predictive analytics. Simultaneously, Distributed Ledger Technology (DLT) saw steady institutional adoption, particularly in real-world asset tokenization and Central Bank Digital Currency (CBDC) pilot programs, introducing new avenues for liquidity and efficiency while posing novel regulatory challenges concerning data privacy and systemic risk.\n",
      "\n",
      "Geopolitical fragmentation intensified, influencing global capital flows, driving 'friend-shoring' strategies for supply chain resilience, and contributing to commodity market volatility. This environment underscored the imperative for domestic economic stability and energy security. Concurrently, sustainable finance matured significantly; the focus shifted from broad ESG mandates to measurable impact, robust climate-related financial risk integration into core frameworks, and the emergence of transition finance. Regulatory bodies adapted by developing new frameworks for AI and digital assets, emphasizing cross-border cooperation and systemic stability. This transformative era has thus forged a financial landscape demanding adaptability, technological embrace, and strategic navigation of complex global dynamics.\n",
      "\n",
      "\n",
      "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mExecution Traces\u001b[0m\u001b[36m \u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[1;36müîç \u001b[0m\u001b[1;36mDetailed execution traces are available!\u001b[0m                                 \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[37mView insights including:\u001b[0m                                                    \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Agent decision-making process\u001b[0m                                           \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Task execution flow and timing\u001b[0m                                          \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Tool usage details\u001b[0m                                                      \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "Would you like to view your execution traces? [y/N] (20s timeout): "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m Tracing Preference Saved \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  Info: Tracing has been disabled.                                            \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  Your preference has been saved. Future Crew/Flow executions will not        \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  collect traces.                                                             \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  To enable tracing later, do any one of these:                               \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set tracing=True in your Crew/Flow code                                   \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file               \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Run: crewai traces enable                                                 \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "# Agent 1: The Scholar\n",
    "scholar = Agent(\n",
    "  role='Senior Research Scholar',\n",
    "  goal='Identify core arguments in {topic}',\n",
    "  backstory='You are an expert at synthesizing academic papers.',\n",
    "  llm=gemini_llm,\n",
    "  allow_delegation=False\n",
    ")\n",
    "\n",
    "# Agent 2: The Writer\n",
    "writer = Agent(\n",
    "  role='Academic Ghostwriter',\n",
    "  goal='Write a formal abstract for {topic}',\n",
    "  backstory='You specialize in clear, peer-reviewed level prose.',\n",
    "  llm=gemini_llm\n",
    ")\n",
    "\n",
    "# Task Definitions\n",
    "task1 = Task(\n",
    "    description='Summarize the last 3 years of {topic}.',\n",
    "    agent=scholar,\n",
    "    expected_output='{\"type\":\"text\",\"key\":\"summary\"}',\n",
    ")\n",
    "task2 = Task(\n",
    "    description='Write a 300-word abstract based on the summary.',\n",
    "    agent=writer,\n",
    "    expected_output='{\"type\":\"text\",\"key\":\"abstract\"}',\n",
    ")\n",
    "\n",
    "# The Crew\n",
    "research_crew = Crew(\n",
    "  agents=[scholar, writer],\n",
    "  tasks=[task1, task2],\n",
    "  process=Process.sequential # Recommended for Free Tier to avoid hitting rate limits\n",
    ")\n",
    "\n",
    "result = research_crew.kickoff(inputs={'topic': 'Finance in 2026'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576d467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:crewai.utilities.llm_utils:Error instantiating LLM from unknown object type: Error importing native provider: OPENAI_API_KEY is required\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Error importing native provider: OPENAI_API_KEY is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llm.py:392\u001b[39m, in \u001b[36mLLM.__new__\u001b[39m\u001b[34m(cls, model, is_litellm, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m     kwargs_copy = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33mprovider\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    391\u001b[39m         Self,\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m         \u001b[43mnative_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_copy\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    393\u001b[39m     )\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py:96\u001b[39m, in \u001b[36mOpenAICompletion.__init__\u001b[39m\u001b[34m(self, model, api_key, base_url, organization, project, timeout, max_retries, default_headers, default_query, client_params, temperature, top_p, frequency_penalty, presence_penalty, max_tokens, max_completion_tokens, seed, stream, response_format, logprobs, top_logprobs, reasoning_effort, provider, interceptor, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m     87\u001b[39m     model=model,\n\u001b[32m     88\u001b[39m     temperature=temperature,\n\u001b[32m   (...)\u001b[39m\u001b[32m     93\u001b[39m     **kwargs,\n\u001b[32m     94\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m client_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_client_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.interceptor:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/openai/completion.py:125\u001b[39m, in \u001b[36mOpenAICompletion._get_client_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY is required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    127\u001b[39m base_params = {\n\u001b[32m    128\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_key,\n\u001b[32m    129\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33morganization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.organization,\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdefault_query\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.default_query,\n\u001b[32m    139\u001b[39m }\n",
      "\u001b[31mValueError\u001b[39m: OPENAI_API_KEY is required",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      6\u001b[39m gemini_llm = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-pro\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# AGENT DEFINITIONS\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Agent 1: The Librarian (Discovery Agent)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m librarian = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mResearch Librarian & Source Discovery Expert\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgoal\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFind and vet the most relevant academic papers for \u001b[39;49m\u001b[38;5;132;43;01m{topic}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackstory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an expert research librarian with a PhD in Information Science. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou specialize in semantic search and source vetting using databases like \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mArXiv, Semantic Scholar, and Google Scholar. You don\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mt just look for keywords; \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myou evaluate papers based on methodological fit, citation impact, and \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelevance to the research question. You\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mre skilled at distinguishing between \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh-quality peer-reviewed work and lower-quality sources.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgemini_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_delegation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Agent 2: The Analyst (Extraction Agent)\u001b[39;00m\n\u001b[32m     30\u001b[39m analyst = Agent(\n\u001b[32m     31\u001b[39m     role=\u001b[33m'\u001b[39m\u001b[33mResearch Analyst & Data Synthesis Expert\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m     goal=\u001b[33m'\u001b[39m\u001b[33mExtract and synthesize key data points, methods, and findings from research papers\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     43\u001b[39m )\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/internal/meta.py:58\u001b[39m, in \u001b[36mAgentMeta.__new__.<locals>.post_init_setup_with_extensions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost_init_setup_with_extensions\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any) -> Any:\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrap post_init_setup to apply extensions after initialization.\u001b[39;00m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \u001b[33;03m        The agent instance\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     a2a_value = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33ma2a\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m a2a_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:225\u001b[39m, in \u001b[36mAgent.post_init_setup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;129m@model_validator\u001b[39m(mode=\u001b[33m\"\u001b[39m\u001b[33mafter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost_init_setup\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28mself\u001b[39m.llm = \u001b[43mcreate_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_calling_llm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mself\u001b[39m.function_calling_llm, BaseLLM\n\u001b[32m    228\u001b[39m     ):\n\u001b[32m    229\u001b[39m         \u001b[38;5;28mself\u001b[39m.function_calling_llm = create_llm(\u001b[38;5;28mself\u001b[39m.function_calling_llm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/llm_utils.py:66\u001b[39m, in \u001b[36mcreate_llm\u001b[39m\u001b[34m(llm_value)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     65\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError instantiating LLM from unknown object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/llm_utils.py:53\u001b[39m, in \u001b[36mcreate_llm\u001b[39m\u001b[34m(llm_value)\u001b[39m\n\u001b[32m     50\u001b[39m     base_url: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mgetattr\u001b[39m(llm_value, \u001b[33m\"\u001b[39m\u001b[33mbase_url\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     51\u001b[39m     api_base: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mgetattr\u001b[39m(llm_value, \u001b[33m\"\u001b[39m\u001b[33mapi_base\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     65\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError instantiating LLM from unknown object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llm.py:397\u001b[39m, in \u001b[36mLLM.__new__\u001b[39m\u001b[34m(cls, model, is_litellm, **kwargs)\u001b[39m\n\u001b[32m    395\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError importing native provider: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# FALLBACK to LiteLLM\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m LITELLM_AVAILABLE:\n",
      "\u001b[31mImportError\u001b[39m: Error importing native provider: OPENAI_API_KEY is required"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "# ---------------------------\n",
    "# AGENT DEFINITIONS\n",
    "# ---------------------------\n",
    "\n",
    "# Agent 1: The Librarian (Discovery Agent)\n",
    "librarian = Agent(\n",
    "    role='Research Librarian & Source Discovery Expert',\n",
    "    goal='Find and vet the most relevant academic papers for {topic}',\n",
    "    backstory=(\n",
    "        \"You are an expert research librarian with a PhD in Information Science. \"\n",
    "        \"You specialize in semantic search and source vetting using databases like \"\n",
    "        \"ArXiv, Semantic Scholar, and Google Scholar. You don't just look for keywords; \"\n",
    "        \"you evaluate papers based on methodological fit, citation impact, and \"\n",
    "        \"relevance to the research question. You're skilled at distinguishing between \"\n",
    "        \"high-quality peer-reviewed work and lower-quality sources.\"\n",
    "    ),\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 2: The Analyst (Extraction Agent)\n",
    "analyst = Agent(\n",
    "    role='Research Analyst & Data Synthesis Expert',\n",
    "    goal='Extract and synthesize key data points, methods, and findings from research papers',\n",
    "    backstory=(\n",
    "        \"You hold a PhD in Data Science and specialize in extracting structured information \"\n",
    "        \"from academic papers. You're expert at identifying key methodologies, sample sizes, \"\n",
    "        \"limitations, and statistical approaches. You create synthesis matrices that allow \"\n",
    "        \"for easy comparison across studies, highlighting both consistencies and contradictions \"\n",
    "        \"in the literature.\"\n",
    "    ),\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 3: The Ghostwriter (Drafting Agent)\n",
    "ghostwriter = Agent(\n",
    "    role='Academic Ghostwriter & Structural Expert',\n",
    "    goal='Draft well-structured academic sections based on synthesized research',\n",
    "    backstory=(\n",
    "        \"You are a professional academic writer with 15 years of experience helping \"\n",
    "        \"researchers publish in top-tier journals. You specialize in creating clear, \"\n",
    "        \"logically structured academic prose with proper flow and transitions. \"\n",
    "        \"You're particularly skilled at turning complex research syntheses into \"\n",
    "        \"accessible, well-organized sections that tell a compelling research story.\"\n",
    "    ),\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 4: The Peer Reviewer (Critique Agent)\n",
    "peer_reviewer = Agent(\n",
    "    role='Skeptical Peer Reviewer & Logical Fallacy Expert',\n",
    "    goal='Critically evaluate drafts for logical consistency, evidence support, and academic rigor',\n",
    "    backstory=(\n",
    "        \"You are a notoriously thorough journal editor known for your 'red team' approach. \"\n",
    "        \"You actively look for weaknesses in arguments, missing citations, logical fallacies, \"\n",
    "        \"and overstatements. You believe that rigorous critique improves research quality. \"\n",
    "        \"You're programmed to be skeptical and demand high evidentiary standards.\"\n",
    "    ),\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent 5: The Formatter (Polish Agent)\n",
    "formatter = Agent(\n",
    "    role='Academic Formatter & Style Editor',\n",
    "    goal='Apply proper formatting and polish to the final document',\n",
    "    backstory=(\n",
    "        \"You are a professional academic editor specializing in APA, MLA, Chicago, and \"\n",
    "        \"other academic style guides. You have an eagle eye for formatting consistency, \"\n",
    "        \"citation accuracy, and 'AI-tell' phrasing. You ensure the final document meets \"\n",
    "        \"publication standards and reads as if written by a human expert.\"\n",
    "    ),\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# TASK DEFINITIONS\n",
    "# ---------------------------\n",
    "\n",
    "# Task 1: Literature Discovery\n",
    "literature_discovery = Task(\n",
    "    description=(\n",
    "        \"For the research topic: '{topic}', find the top 10-15 most relevant academic papers \"\n",
    "        \"from the last 5 years. Focus on papers with strong methodological approaches and \"\n",
    "        \"high citation impact. Evaluate each paper on:\\n\"\n",
    "        \"1. Relevance to the research question (0-10)\\n\"\n",
    "        \"2. Methodological rigor (0-10)\\n\"\n",
    "        \"3. Citation impact (0-10)\\n\"\n",
    "        \"4. Key findings\\n\"\n",
    "        \"5. Research gaps identified\\n\\n\"\n",
    "        \"Create a curated bibliography with PDF links where available and a brief \"\n",
    "        \"justification for each paper's inclusion.\"\n",
    "    ),\n",
    "    agent=librarian,\n",
    "    expected_output=(\n",
    "        \"A structured report containing:\\n\"\n",
    "        \"1. Total papers reviewed\\n\"\n",
    "        \"2. Top 10-15 selected papers with full citations\\n\"\n",
    "        \"3. For each paper: Relevance Score, Method Score, Impact Score (all 0-10)\\n\"\n",
    "        \"4. Brief summary of why each paper was selected\\n\"\n",
    "        \"5. Overall research trends and gaps identified\"\n",
    "    ),\n",
    "    output_file=\"literature_discovery.md\"\n",
    ")\n",
    "\n",
    "# Task 2: Data Extraction & Synthesis\n",
    "data_synthesis = Task(\n",
    "    description=(\n",
    "        \"Using the papers identified by the Librarian, create a detailed synthesis matrix. \"\n",
    "        \"For each paper, extract:\\n\"\n",
    "        \"1. Research question/hypothesis\\n\"\n",
    "        \"2. Methodology (quantitative/qualitative/mixed, specific methods used)\\n\"\n",
    "        \"3. Sample size and characteristics\\n\"\n",
    "        \"4. Key findings and conclusions\\n\"\n",
    "        \"5. Limitations acknowledged\\n\"\n",
    "        \"6. Statistical significance and effect sizes (if applicable)\\n\"\n",
    "        \"7. Theoretical framework\\n\\n\"\n",
    "        \"Organize this into a comparative table that highlights:\\n\"\n",
    "        \"- Methodological consistencies/inconsistencies\\n\"\n",
    "        \"- Converging/diverging findings\\n\"\n",
    "        \"- Evolution of the field over time\\n\"\n",
    "        \"- Major gaps in the literature\"\n",
    "    ),\n",
    "    agent=analyst,\n",
    "    context=[literature_discovery],\n",
    "    expected_output=(\n",
    "        \"A comprehensive synthesis matrix in table format with:\\n\"\n",
    "        \"1. Row for each paper with extracted data points\\n\"\n",
    "        \"2. Summary of methodological trends\\n\"\n",
    "        \"3. Summary of findings convergence/divergence\\n\"\n",
    "        \"4. Visual comparison of sample sizes, methods, etc.\\n\"\n",
    "        \"5. Identified research gaps and contradictions\"\n",
    "    ),\n",
    "    output_file=\"data_synthesis.md\"\n",
    ")\n",
    "\n",
    "# Task 3: Literature Review Draft\n",
    "draft_literature_review = Task(\n",
    "    description=(\n",
    "        \"Using the synthesis matrix from the Analyst, draft a comprehensive literature review \"\n",
    "        \"section for a paper on '{topic}'. The literature review should:\\n\"\n",
    "        \"1. Begin with an introduction to the field\\n\"\n",
    "        \"2. Organize papers thematically/methodologically/chronologically\\n\"\n",
    "        \"3. Compare and contrast different studies\\n\"\n",
    "        \"4. Highlight methodological strengths and weaknesses\\n\"\n",
    "        \"5. Identify gaps in current research\\n\"\n",
    "        \"6. Lead logically to potential research questions\\n\"\n",
    "        \"7. Be approximately 1500-2000 words\\n\\n\"\n",
    "        \"Ensure proper academic tone, logical flow between paragraphs, and \"\n",
    "        \"appropriate use of transition words. Include in-text citations for all claims.\"\n",
    "    ),\n",
    "    agent=ghostwriter,\n",
    "    context=[data_synthesis],\n",
    "    expected_output=(\n",
    "        \"A well-structured literature review draft in markdown format with:\\n\"\n",
    "        \"1. Clear introduction establishing the field\\n\"\n",
    "        \"2. Thematic organization of existing research\\n\"\n",
    "        \"3. Critical analysis of methodologies and findings\\n\"\n",
    "        \"4. Clear identification of research gaps\\n\"\n",
    "        \"5. Logical conclusion that sets up future research\\n\"\n",
    "        \"6. Proper in-text citations throughout\"\n",
    "    ),\n",
    "    output_file=\"literature_review_draft.md\"\n",
    ")\n",
    "\n",
    "# Task 4: Peer Review Critique\n",
    "peer_review_critique = Task(\n",
    "    description=(\n",
    "        \"Critically review the literature review draft. Be thorough and skeptical. Identify:\\n\"\n",
    "        \"1. Any claims that lack sufficient evidence from the synthesis matrix\\n\"\n",
    "        \"2. Logical fallacies or overgeneralizations\\n\"\n",
    "        \"3. Missing citations for key claims\\n\"\n",
    "        \"4. Methodological critiques that should be included\\n\"\n",
    "        \"5. Alternative interpretations of the data\\n\"\n",
    "        \"6. Sections that need more elaboration\\n\"\n",
    "        \"7. Any potential biases in interpretation\\n\\n\"\n",
    "        \"For each issue found, provide:\\n\"\n",
    "        \"- The specific problematic text\\n\"\n",
    "        \"- Why it's problematic\\n\"\n",
    "        \"- Specific suggestions for improvement\\n\"\n",
    "        \"- Supporting evidence from the synthesis matrix\"\n",
    "    ),\n",
    "    agent=peer_reviewer,\n",
    "    context=[draft_literature_review, data_synthesis],\n",
    "    expected_output=(\n",
    "        \"A detailed peer review report containing:\\n\"\n",
    "        \"1. Overall assessment of the draft\\n\"\n",
    "        \"2. List of major issues (with specific examples)\\n\"\n",
    "        \"3. List of minor issues\\n\"\n",
    "        \"4. Specific revision suggestions\\n\"\n",
    "        \"5. Priority level for each revision (Critical/Important/Minor)\\n\"\n",
    "        \"6. Estimated time needed for revisions\"\n",
    "    ),\n",
    "    output_file=\"peer_review_report.md\"\n",
    ")\n",
    "\n",
    "# Task 5: Revised Draft (with iterative feedback loop)\n",
    "revised_draft = Task(\n",
    "    description=(\n",
    "        \"Rewrite the literature review based on the peer review feedback. Address ALL \"\n",
    "        \"critical and important issues identified by the Peer Reviewer. Specifically:\\n\"\n",
    "        \"1. Add missing citations for all claims\\n\"\n",
    "        \"2. Strengthen weak arguments with evidence from the synthesis matrix\\n\"\n",
    "        \"3. Correct any logical fallacies or overgeneralizations\\n\"\n",
    "        \"4. Include methodological critiques where suggested\\n\"\n",
    "        \"5. Ensure balanced interpretation of the data\\n\"\n",
    "        \"6. Elaborate on sections marked as needing more detail\\n\\n\"\n",
    "        \"Track all changes made in response to the peer review and provide a \"\n",
    "        \"brief explanation of how each issue was addressed.\"\n",
    "    ),\n",
    "    agent=ghostwriter,\n",
    "    context=[draft_literature_review, peer_review_critique],\n",
    "    expected_output=(\n",
    "        \"A revised literature review draft with:\\n\"\n",
    "        \"1. All peer review issues addressed\\n\"\n",
    "        \"2. Change log documenting revisions\\n\"\n",
    "        \"3. Stronger evidence-based arguments\\n\"\n",
    "        \"4. More balanced and nuanced analysis\\n\"\n",
    "        \"5. Proper academic rigor throughout\"\n",
    "    ),\n",
    "    output_file=\"revised_literature_review.md\"\n",
    ")\n",
    "\n",
    "# Task 6: Final Formatting and Polish\n",
    "final_polish = Task(\n",
    "    description=(\n",
    "        \"Take the revised literature review and apply final formatting and polish:\\n\"\n",
    "        \"1. Apply {citation_style} formatting to all citations and references\\n\"\n",
    "        \"2. Check for and eliminate any 'AI-tell' repetitive phrasing\\n\"\n",
    "        \"3. Ensure consistent academic tone throughout\\n\"\n",
    "        \"4. Verify all citations match the bibliography\\n\"\n",
    "        \"5. Add proper section headings and formatting\\n\"\n",
    "        \"6. Create a properly formatted reference list\\n\"\n",
    "        \"7. Add a title page with appropriate metadata\\n\"\n",
    "        \"8. Ensure the document is publication-ready\"\n",
    "    ),\n",
    "    agent=formatter,\n",
    "    context=[revised_draft],\n",
    "    expected_output=(\n",
    "        \"A fully polished, publication-ready literature review with:\\n\"\n",
    "        \"1. Proper {citation_style} formatting\\n\"\n",
    "        \"2. Consistent academic tone\\n\"\n",
    "        \"3. Complete and accurate reference list\\n\"\n",
    "        \"4. Professional formatting and layout\\n\"\n",
    "        \"5. No repetitive or unnatural phrasing\"\n",
    "    ),\n",
    "    output_file=\"final_literature_review.md\"\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# CREW ASSEMBLY\n",
    "# ---------------------------\n",
    "\n",
    "# Create the Research Lab Crew\n",
    "research_lab = Crew(\n",
    "    agents=[librarian, analyst, ghostwriter, peer_reviewer, formatter],\n",
    "    tasks=[\n",
    "        literature_discovery,\n",
    "        data_synthesis,\n",
    "        draft_literature_review,\n",
    "        peer_review_critique,\n",
    "        revised_draft,\n",
    "        final_polish\n",
    "    ],\n",
    "    process=Process.sequential,  # Sequential to mimic the research workflow\n",
    "    verbose=True,\n",
    "    memory=True  # Enable memory so agents can reference previous work\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# EXECUTION\n",
    "# ---------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input parameters\n",
    "    research_topic = \"The impact of AI on academic research productivity\"\n",
    "    citation_style = \"APA 7th edition\"  # Can be changed to MLA, Chicago, etc.\n",
    "    \n",
    "    # Execute the crew\n",
    "    print(f\"Starting Research Lab for topic: {research_topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    inputs = {\n",
    "        'topic': research_topic,\n",
    "        'citation_style': citation_style\n",
    "    }\n",
    "    \n",
    "    result = research_lab.kickoff(inputs=inputs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESEARCH COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nOutput files created:\")\n",
    "    print(\"1. literature_discovery.md - Initial paper discovery\")\n",
    "    print(\"2. data_synthesis.md - Synthesis matrix\")\n",
    "    print(\"3. literature_review_draft.md - First draft\")\n",
    "    print(\"4. peer_review_report.md - Critique feedback\")\n",
    "    print(\"5. revised_literature_review.md - Revised draft\")\n",
    "    print(\"6. final_literature_review.md - Polished final version\")\n",
    "    print(\"\\nFinal result summary:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99ad47ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crew Execution Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">6a737059-9b64-4105-89f5-169a7d02569b</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">‚îÇ</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m6a737059-9b64-4105-89f5-169a7d02569b\u001b[0m                                                                       \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚îÇ\u001b[0m                                                                                                                 \u001b[36m‚îÇ\u001b[0m\n",
       "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ü§ñ Agent Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Academic Librarian</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Find the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF </span>      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">links and Relevance Score for each.</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m‚ï≠‚îÄ\u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m ü§ñ Agent Started \u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mAcademic Librarian\u001b[0m                                                                                      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mFind the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF \u001b[0m      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[92mlinks and Relevance Score for each.\u001b[0m                                                                            \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e5028514/code/.venv/lib/python3.12/site-packages/rich/live.py:256: UserWarning: install \"ipywidgets\" for Jupyter support\n",
      "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16963fe30>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x17ffa67d0> server_hostname='generativelanguage.googleapis.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x309097320>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:19:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=44'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "ERROR:root:Google Gemini API error: 400 - API key not valid. Please pass a valid API key.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n",
      "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\u001b[0m\n",
      "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n",
      "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LLM Error ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">‚ùå LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">Google Gemini API error: 400 - API key not valid. Please pass a valid API key.</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[1;31m‚ùå LLM Call Failed\u001b[0m                                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mGoogle Gemini API error: 400 - API key not valid. Please pass a valid API key.\u001b[0m                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ü§ñ Agent Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Academic Librarian</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Find the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF </span>      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">links and Relevance Score for each.</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m‚ï≠‚îÄ\u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m ü§ñ Agent Started \u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mAcademic Librarian\u001b[0m                                                                                      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mFind the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF \u001b[0m      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[92mlinks and Relevance Score for each.\u001b[0m                                                                            \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:19:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=41'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "ERROR:root:Google Gemini API error: 400 - API key not valid. Please pass a valid API key.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">An unknown error occurred. Please check the details below.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">Error details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">{'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">Please pass a valid API key.'}]}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API\u001b[0m\n",
       "\u001b[91mkey.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': \u001b[0m\n",
       "\u001b[91m'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, \u001b[0m\n",
       "\u001b[91m{'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. \u001b[0m\n",
       "\u001b[91mPlease pass a valid API key.'}]}}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">An unknown error occurred. Please check the details below.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">Error details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">{'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. </span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">Please pass a valid API key.'}]}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API\u001b[0m\n",
       "\u001b[91mkey.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': \u001b[0m\n",
       "\u001b[91m'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, \u001b[0m\n",
       "\u001b[91m{'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. \u001b[0m\n",
       "\u001b[91mPlease pass a valid API key.'}]}}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ü§ñ Agent Started ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Academic Librarian</span>                                                                                      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Find the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF </span>      <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">links and Relevance Score for each.</span>                                                                            <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">‚îÇ</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m‚ï≠‚îÄ\u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m ü§ñ Agent Started \u001b[0m\u001b[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[35m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mAcademic Librarian\u001b[0m                                                                                      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mFind the top 10 most relevant papers for Finance in 2026. Focus on methodological fit. Provide PDF \u001b[0m      \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m  \u001b[92mlinks and Relevance Score for each.\u001b[0m                                                                            \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚îÇ\u001b[0m                                                                                                                 \u001b[35m‚îÇ\u001b[0m\n",
       "\u001b[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LLM Error ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">‚ùå LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">Google Gemini API error: 400 - API key not valid. Please pass a valid API key.</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[1;31m‚ùå LLM Call Failed\u001b[0m                                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mGoogle Gemini API error: 400 - API key not valid. Please pass a valid API key.\u001b[0m                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:19:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=42'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 400 Bad Request\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "ERROR:root:Google Gemini API error: 400 - API key not valid. Please pass a valid API key.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n",
      "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\u001b[0m\n",
      "\u001b[91mAn unknown error occurred. Please check the details below.\u001b[0m\n",
      "\u001b[91mError details: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LLM Error ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">‚ùå LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">Google Gemini API error: 400 - API key not valid. Please pass a valid API key.</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[1;31m‚ùå LLM Call Failed\u001b[0m                                                                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mGoogle Gemini API error: 400 - API key not valid. Please pass a valid API key.\u001b[0m                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Task Failure ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Task Failed</span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">891a9944-6a81-4d47-aeb2-5d8d9f059b49</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #800000; text-decoration-color: #800000\">Academic Librarian</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31m891a9944-6a81-4d47-aeb2-5d8d9f059b49\u001b[0m                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mAcademic Librarian\u001b[0m                                                                                      \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Crew Failure ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Crew Execution Failed</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">crew</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #800000; text-decoration-color: #800000\">6a737059-9b64-4105-89f5-169a7d02569b</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: </span>                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                                     \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31m6a737059-9b64-4105-89f5-169a7d02569b\u001b[0m                                                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m  \u001b[37mFinal Output: \u001b[0m                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Execute the workflow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m result = \u001b[43mresearch_crew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFinance in 2026\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:755\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.sequential:\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:995\u001b[39m, in \u001b[36mCrew._run_sequential_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:1103\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m   1102\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1108\u001b[39m task_outputs.append(task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:458\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:591\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    590\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:522\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    521\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrails \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:525\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    517\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    518\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    519\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         ),\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    526\u001b[39m result = \u001b[38;5;28mself\u001b[39m.execute_task(task, context, tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:490\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    493\u001b[39m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:598\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAgent executor is not initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:188\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:299\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m     handle_unknown_error(\u001b[38;5;28mself\u001b[39m._printer, e)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:229\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    227\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m formatted_answer = process_llm_response(answer, \u001b[38;5;28mself\u001b[39m.use_stop_words)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:276\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:268\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:255\u001b[39m, in \u001b[36mGeminiCompletion.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_streaming_completion(\n\u001b[32m    247\u001b[39m             formatted_content,\n\u001b[32m    248\u001b[39m             config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m             response_model,\n\u001b[32m    253\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformatted_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:426\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    425\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededError(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._track_token_usage_internal(usage)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:419\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m     usage = \u001b[38;5;28mself\u001b[39m._extract_token_usage(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mgenerate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   tools = config.get(\u001b[33m'\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m'\u001b[39m, [])\n\u001b[32m   5204\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m tools:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:3985\u001b[39m, in \u001b[36m_generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3984\u001b[39m   path = '{model}:generateContent'.format_map(request_url_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m else:\n\u001b[32m   3986\u001b[39m   path = '{model}:generateContent'\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1224\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Execute the workflow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m result = \u001b[43mresearch_crew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFinance in 2026\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:755\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.sequential:\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:995\u001b[39m, in \u001b[36mCrew._run_sequential_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:1103\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m   1102\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1108\u001b[39m task_outputs.append(task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:458\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:591\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    590\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:522\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    521\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrails \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:525\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    517\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    518\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    519\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         ),\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    526\u001b[39m result = \u001b[38;5;28mself\u001b[39m.execute_task(task, context, tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:490\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    493\u001b[39m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:598\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAgent executor is not initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:188\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:299\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m     handle_unknown_error(\u001b[38;5;28mself\u001b[39m._printer, e)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:229\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    227\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m formatted_answer = process_llm_response(answer, \u001b[38;5;28mself\u001b[39m.use_stop_words)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:276\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:268\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:255\u001b[39m, in \u001b[36mGeminiCompletion.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_streaming_completion(\n\u001b[32m    247\u001b[39m             formatted_content,\n\u001b[32m    248\u001b[39m             config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m             response_model,\n\u001b[32m    253\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformatted_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:426\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    425\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededError(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._track_token_usage_internal(usage)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:419\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m     usage = \u001b[38;5;28mself\u001b[39m._extract_token_usage(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mgenerate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   tools = config.get(\u001b[33m'\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m'\u001b[39m, [])\n\u001b[32m   5204\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m tools:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:3985\u001b[39m, in \u001b[36m_generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3984\u001b[39m   path = '{model}:generateContent'.format_map(request_url_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m else:\n\u001b[32m   3986\u001b[39m   path = '{model}:generateContent'\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1224\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    100\u001b[39m research_crew = Crew(\n\u001b[32m    101\u001b[39m     agents=[librarian, analyst, ghostwriter, reviewer, polisher],\n\u001b[32m    102\u001b[39m     tasks=[\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    112\u001b[39m )\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Execute the workflow\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m result = \u001b[43mresearch_crew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtopic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFinance in 2026\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:755\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_crew_planning()\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.sequential:\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n\u001b[32m    757\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_hierarchical_process()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:995\u001b[39m, in \u001b[36mCrew._run_sequential_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CrewOutput:\n\u001b[32m    994\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/crew.py:1103\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m   1100\u001b[39m     futures.clear()\n\u001b[32m   1102\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1108\u001b[39m task_outputs.append(task_output)\n\u001b[32m   1109\u001b[39m \u001b[38;5;28mself\u001b[39m._process_task_result(task, task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:458\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sync\u001b[39m(\n\u001b[32m    452\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    453\u001b[39m     agent: BaseAgent | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    454\u001b[39m     context: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    455\u001b[39m     tools: \u001b[38;5;28mlist\u001b[39m[BaseTool] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    456\u001b[39m ) -> TaskOutput:\n\u001b[32m    457\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:591\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;28mself\u001b[39m.end_time = datetime.datetime.now()\n\u001b[32m    590\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m591\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/task.py:522\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    520\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_by_agents.add(agent.role)\n\u001b[32m    521\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrails \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._guardrail:\n\u001b[32m    529\u001b[39m     pydantic_output, json_output = \u001b[38;5;28mself\u001b[39m._export_output(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    517\u001b[39m         crewai_event_bus.emit(\n\u001b[32m    518\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    519\u001b[39m             event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m             ),\n\u001b[32m    524\u001b[39m         )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n\u001b[32m    529\u001b[39m     \u001b[38;5;28mself\u001b[39m._rpm_controller.stop_rpm_counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:526\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    517\u001b[39m         crewai_event_bus.emit(\n\u001b[32m    518\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    519\u001b[39m             event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m             ),\n\u001b[32m    524\u001b[39m         )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n\u001b[32m    529\u001b[39m     \u001b[38;5;28mself\u001b[39m._rpm_controller.stop_rpm_counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:525\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._times_executed > \u001b[38;5;28mself\u001b[39m.max_retry_limit:\n\u001b[32m    517\u001b[39m         crewai_event_bus.emit(\n\u001b[32m    518\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    519\u001b[39m             event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m             ),\n\u001b[32m    524\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    526\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.execute_task(task, context, tools)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_rpm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rpm_controller:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:490\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    486\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._execute_with_timeout(\n\u001b[32m    487\u001b[39m             task_prompt, task, \u001b[38;5;28mself\u001b[39m.max_execution_time\n\u001b[32m    488\u001b[39m         )\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    493\u001b[39m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n\u001b[32m    494\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    495\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    496\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    500\u001b[39m         ),\n\u001b[32m    501\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agent/core.py:598\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agent_executor:\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAgent executor is not initialized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:188\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m.ask_for_human_input = \u001b[38;5;28mbool\u001b[39m(inputs.get(\u001b[33m\"\u001b[39m\u001b[33mask_for_human_input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m._printer.print(\n\u001b[32m    191\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    192\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    193\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:299\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    298\u001b[39m     handle_unknown_error(\u001b[38;5;28mself\u001b[39m._printer, e)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:229\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    227\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m formatted_answer = process_llm_response(answer, \u001b[38;5;28mself\u001b[39m.use_stop_words)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m# Extract agent fingerprint if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:276\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    268\u001b[39m     answer = llm.call(\n\u001b[32m    269\u001b[39m         messages,\n\u001b[32m    270\u001b[39m         callbacks=callbacks,\n\u001b[32m   (...)\u001b[39m\u001b[32m    273\u001b[39m         response_model=response_model,\n\u001b[32m    274\u001b[39m     )\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[32m    278\u001b[39m     printer.print(\n\u001b[32m    279\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mReceived None or empty response from LLM call.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    280\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    281\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:268\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer, from_task, from_agent, response_model, executor_context)\u001b[39m\n\u001b[32m    265\u001b[39m     messages = executor_context.messages\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:255\u001b[39m, in \u001b[36mGeminiCompletion.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_streaming_completion(\n\u001b[32m    247\u001b[39m             formatted_content,\n\u001b[32m    248\u001b[39m             config,\n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m             response_model,\n\u001b[32m    253\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformatted_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mavailable_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    266\u001b[39m     error_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGoogle Gemini API error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:426\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    424\u001b[39m         logging.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mContext window exceeded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    425\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededError(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28mself\u001b[39m._track_token_usage_internal(usage)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.candidates \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.tools \u001b[38;5;129;01mor\u001b[39;00m available_functions):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/crewai/llms/providers/gemini/completion.py:419\u001b[39m, in \u001b[36mGeminiCompletion._handle_completion\u001b[39m\u001b[34m(self, contents, system_instruction, config, available_functions, from_task, from_agent, response_model)\u001b[39m\n\u001b[32m    412\u001b[39m api_params = {\n\u001b[32m    413\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    414\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m\"\u001b[39m: contents,\n\u001b[32m    415\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: config,\n\u001b[32m    416\u001b[39m }\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mapi_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m     usage = \u001b[38;5;28mself\u001b[39m._extract_token_usage(response)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mgenerate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5201\u001b[39m     original_tools_length = \u001b[38;5;28mlen\u001b[39m(config.tools)\n\u001b[32m   5202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   tools = config.get(\u001b[33m'\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m'\u001b[39m, [])\n\u001b[32m   5204\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m tools:\n\u001b[32m   5205\u001b[39m     original_tools_length = \u001b[38;5;28mlen\u001b[39m(tools)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/models.py:3985\u001b[39m, in \u001b[36m_generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3983\u001b[39m   if request_url_dict:\n\u001b[32m   3984\u001b[39m     path = '{model}:generateContent'.format_map(request_url_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m   else:\n\u001b[32m   3986\u001b[39m     path = '{model}:generateContent'\n\u001b[32m   3987\u001b[39m else:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1380\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1383\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1384\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1385\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m   response_body = (\n\u001b[32m   1390\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m   )\n\u001b[32m   1392\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1224\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.11/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1194\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m       method=http_request.method,\n\u001b[32m   1196\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/.venv/lib/python3.12/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'API key not valid. Please pass a valid API key.', 'status': 'INVALID_ARGUMENT', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'API_KEY_INVALID', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com'}}, {'@type': 'type.googleapis.com/google.rpc.LocalizedMessage', 'locale': 'en-US', 'message': 'API key not valid. Please pass a valid API key.'}]}}"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Tracing Status ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>  Info: Tracing is disabled.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>  To enable tracing, do any one of these:                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>  ‚Ä¢ Set tracing=True in your Crew/Flow code                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>  ‚Ä¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file                                                  <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>  ‚Ä¢ Run: crewai traces enable                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">‚îÇ</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m Tracing Status \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m                                                                                                                 \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m  Info: Tracing is disabled.                                                                                     \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m                                                                                                                 \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m  To enable tracing, do any one of these:                                                                        \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set tracing=True in your Crew/Flow code                                                                      \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file                                                  \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Run: crewai traces enable                                                                                    \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚îÇ\u001b[0m                                                                                                                 \u001b[34m‚îÇ\u001b[0m\n",
       "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[36m‚ï≠‚îÄ\u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mExecution Traces\u001b[0m\u001b[36m \u001b[0m\u001b[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[36m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[1;36müîç \u001b[0m\u001b[1;36mDetailed execution traces are available!\u001b[0m                                 \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[37mView insights including:\u001b[0m                                                    \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Agent decision-making process\u001b[0m                                           \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Task execution flow and timing\u001b[0m                                          \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m  \u001b[94m  ‚Ä¢ Tool usage details\u001b[0m                                                      \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚îÇ\u001b[0m                                                                              \u001b[36m‚îÇ\u001b[0m\n",
      "\u001b[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "Would you like to view your execution traces? [y/N] (20s timeout): "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://telemetry.crewai.com:4319 \"POST /v1/traces HTTP/1.1\" 200 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[34m‚ï≠‚îÄ\u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m Tracing Preference Saved \u001b[0m\u001b[34m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[34m‚îÄ‚ïÆ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  Info: Tracing has been disabled.                                            \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  Your preference has been saved. Future Crew/Flow executions will not        \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  collect traces.                                                             \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  To enable tracing later, do any one of these:                               \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set tracing=True in your Crew/Flow code                                   \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file               \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m  ‚Ä¢ Run: crewai traces enable                                                 \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚îÇ\u001b[0m                                                                              \u001b[34m‚îÇ\u001b[0m\n",
      "\u001b[34m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "# Initialize Gemini LLM (make sure you have the proper setup)\n",
    "# Assuming gemini_llm is already defined as per your code\n",
    "\n",
    "### AGENT DEFINITIONS ###\n",
    "\n",
    "# Agent 1: The Librarian (Discovery Agent)\n",
    "librarian = Agent(\n",
    "    role='Academic Librarian',\n",
    "    goal='Find top 10 most relevant papers for {topic} using semantic search',\n",
    "    backstory='Expert in semantic search and source vetting. Uses methodological fit rather than just keywords.',\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Agent 2: The Analyst (Extraction Agent)\n",
    "analyst = Agent(\n",
    "    role='Research Analyst',\n",
    "    goal='Extract data, formulas, and limitations from papers into structured synthesis matrix',\n",
    "    backstory='Specializes in data and method synthesis from academic literature.',\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Agent 3: The Ghostwriter (Drafting Agent)\n",
    "ghostwriter = Agent(\n",
    "    role='Academic Ghostwriter',\n",
    "    goal='Draft specific sections (Introduction, Literature Review) from synthesis matrix',\n",
    "    backstory='Specializes in academic tone, structure, and logical flow.',\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Agent 4: The Peer Reviewer (Critique Agent)\n",
    "reviewer = Agent(\n",
    "    role='Skeptical Peer Reviewer',\n",
    "    goal='Critique drafts for logical fallacies, missing citations, and inconsistencies',\n",
    "    backstory='Programmed to be skeptical. Identifies gaps between claims and evidence.',\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "# Agent 5: The Polisher (Formatting Agent)\n",
    "polisher = Agent(\n",
    "    role='Academic Polisher',\n",
    "    goal='Ensure proper formatting (APA/MLA) and remove AI-style repetitive phrasing',\n",
    "    backstory='Expert in academic formatting standards and natural academic prose.',\n",
    "    llm=gemini_llm,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "### TASK DEFINITIONS ###\n",
    "\n",
    "# Phase 1: Discovery\n",
    "task_discovery = Task(\n",
    "    description='Find the top 10 most relevant papers for {topic}. Focus on methodological fit. Provide PDF links and Relevance Score for each.',\n",
    "    agent=librarian,\n",
    "    expected_output='Curated list of 10 papers with URLs and Relevance Scores (1-10)'\n",
    ")\n",
    "\n",
    "# Phase 1: Analysis\n",
    "task_analysis = Task(\n",
    "    description='Read the papers from the Librarian. Extract data points, formulas, limitations into structured synthesis matrix: Paper, Method, Sample Size, Key Findings, Limitations.',\n",
    "    agent=analyst,\n",
    "    expected_output='Synthesis matrix table with columns: Paper, Method, Sample Size, Key Findings, Limitations'\n",
    ")\n",
    "\n",
    "# Phase 2: Drafting (with loop capability)\n",
    "task_draft_intro = Task(\n",
    "    description='Using the synthesis matrix from the Analyst, draft the Introduction section for {topic}.',\n",
    "    agent=ghostwriter,\n",
    "    expected_output='Rough Markdown draft of Introduction section'\n",
    ")\n",
    "\n",
    "# Phase 3: Review (Critique)\n",
    "task_review_intro = Task(\n",
    "    description='Critique the Introduction draft. Identify: 1) Claims not supported by Analyst data, 2) Missing citations, 3) Logical gaps.',\n",
    "    agent=reviewer,\n",
    "    expected_output='List of Required Revisions with specific issues found'\n",
    ")\n",
    "\n",
    "# Phase 4: Rewrite (Conditional - only if revisions needed)\n",
    "task_rewrite_intro = Task(\n",
    "    description='Rewrite the Introduction section addressing ALL revisions from the Peer Reviewer.',\n",
    "    agent=ghostwriter,\n",
    "    expected_output='Revised Introduction section'\n",
    ")\n",
    "\n",
    "# Phase 5: Final Polish\n",
    "task_polish_final = Task(\n",
    "    description='Apply APA/MLA formatting to the final paper. Remove repetitive phrasing and ensure academic tone.',\n",
    "    agent=polisher,\n",
    "    expected_output='Final polished paper with proper formatting'\n",
    ")\n",
    "\n",
    "### THE WORKFLOW CREW ###\n",
    "\n",
    "# Main research crew with sequential process\n",
    "research_crew = Crew(\n",
    "    agents=[librarian, analyst, ghostwriter, reviewer, polisher],\n",
    "    tasks=[\n",
    "        task_discovery,\n",
    "        task_analysis,\n",
    "        task_draft_intro,\n",
    "        task_review_intro,\n",
    "        task_rewrite_intro,\n",
    "        task_polish_final\n",
    "    ],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Execute the workflow\n",
    "result = research_crew.kickoff(inputs={'topic': 'Finance in 2026'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f46646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
